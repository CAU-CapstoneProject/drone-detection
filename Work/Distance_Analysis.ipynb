{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance Analysis\n",
    "# 25m 45m 65m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale, robust_scale, minmax_scale, maxabs_scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "import numpy as np\n",
    "import glob\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "model = joblib.load(\"10252018_randomforest_bee2drone_n_sc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "#drone_path = \"/Users/junhyuckwoo/capstone/TestFile/ProceedData/phantom2_44100_1s/*.wav\"\n",
    "drone_path = \"/Users/junhyuckwoo/capstone/TestFile/Data/DistanceTest/Syma/*.wav\"\n",
    "drone_files = glob.glob(drone_path)\n",
    "drone_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87, 7)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Data - 15m\n",
    "data,sr = librosa.load(drone_files[0], sr=44100)\n",
    "norm = maxabs_scale(data[:44100])\n",
    "drone = librosa.feature.spectral_contrast(norm).T\n",
    "drone.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_d = np.ones(len(drone))\n",
    "y_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 10282018_randomforest_bee2drone_n_sc.pkl\n",
      "F-Score: 0.989\n",
      "Accuracy:  0.9885057471264368\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         0\n",
      "        1.0       1.00      0.99      0.99        87\n",
      "\n",
      "avg / total       1.00      0.99      0.99        87\n",
      "\n",
      "[[ 0  0]\n",
      " [ 1 86]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junhyuckwoo/capstone/lib/python3.5/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(drone)\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "p,r,f,s = precision_recall_fscore_support(y_d, prediction, average='micro')\n",
    "print(\"Model: 10282018_randomforest_bee2drone_n_sc.pkl\")\n",
    "print(\"F-Score:\", round(f,3))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy: \", accuracy_score(y_d, prediction))\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_d, prediction))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_d, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87, 7)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Data - 25m\n",
    "data,sr = librosa.load(drone_files[1], sr=44100)\n",
    "norm = maxabs_scale(data[:44100])\n",
    "drone = librosa.feature.spectral_contrast(norm).T\n",
    "drone.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 10282018_randomforest_bee2drone_n_sc.pkl\n",
      "F-Score: 0.885\n",
      "Accuracy:  0.8850574712643678\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         0\n",
      "        1.0       1.00      0.89      0.94        87\n",
      "\n",
      "avg / total       1.00      0.89      0.94        87\n",
      "\n",
      "[[ 0  0]\n",
      " [10 77]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junhyuckwoo/capstone/lib/python3.5/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(drone)\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "p,r,f,s = precision_recall_fscore_support(y_d, prediction, average='micro')\n",
    "print(\"Model: 10282018_randomforest_bee2drone_n_sc.pkl\")\n",
    "print(\"F-Score:\", round(f,3))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy: \", accuracy_score(y_d, prediction))\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_d, prediction))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_d, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87, 7)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Data - 45m\n",
    "data,sr = librosa.load(drone_files[2], sr=44100)\n",
    "norm = maxabs_scale(data[:44100])\n",
    "drone = librosa.feature.spectral_contrast(norm).T\n",
    "drone.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 10282018_randomforest_bee2drone_n_sc.pkl\n",
      "F-Score: 0.115\n",
      "Accuracy:  0.11494252873563218\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         0\n",
      "        1.0       1.00      0.11      0.21        87\n",
      "\n",
      "avg / total       1.00      0.11      0.21        87\n",
      "\n",
      "[[ 0  0]\n",
      " [77 10]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junhyuckwoo/capstone/lib/python3.5/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(drone)\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "p,r,f,s = precision_recall_fscore_support(y_d, prediction, average='micro')\n",
    "print(\"Model: 10282018_randomforest_bee2drone_n_sc.pkl\")\n",
    "print(\"F-Score:\", round(f,3))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy: \", accuracy_score(y_d, prediction))\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_d, prediction))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_d, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87, 7)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Data - 65m\n",
    "data,sr = librosa.load(drone_files[3], sr=44100)\n",
    "norm = maxabs_scale(data[:44100])\n",
    "drone = librosa.feature.spectral_contrast(norm).T\n",
    "drone.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 10282018_randomforest_bee2drone_n_sc.pkl\n",
      "F-Score: 0.046\n",
      "Accuracy:  0.04597701149425287\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         0\n",
      "        1.0       1.00      0.05      0.09        87\n",
      "\n",
      "avg / total       1.00      0.05      0.09        87\n",
      "\n",
      "[[ 0  0]\n",
      " [83  4]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junhyuckwoo/capstone/lib/python3.5/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(drone)\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "p,r,f,s = precision_recall_fscore_support(y_d, prediction, average='micro')\n",
    "print(\"Model: 10282018_randomforest_bee2drone_n_sc.pkl\")\n",
    "print(\"F-Score:\", round(f,3))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy: \", accuracy_score(y_d, prediction))\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_d, prediction))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_d, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
